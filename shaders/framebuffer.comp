#version 460 core
layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;
layout(rgba32f, binding = 0) uniform image2D screen;
uniform float f_time;
uniform uint u_time;

const float EPSILON = 0.000001;
const float TMIN = 0.001;
const float TMAX = 10000.0;
const float ENVIRONMENT_MAP_LE = 1.0;
const float PI = 3.14159265;
const uint BOUNCE_COUNT = 5;
const uint NUM_SAMPLES = 100;

uvec2 seed_vec;
float fract_time;

float hash_to_float(uint hash)
{
	return hash * (1.0 / float(0xffffffffu));
}

vec2 hash_uvec2_to_vec2(uvec2 hash)
{
	return vec2(hash) * (1.0 / float(0xffffffffu));
}

uint pcg(uint v)
{
	uint state = v * 747796405u + 2891336453u;
	uint word = ((state >> ((state >> 28u) + 4u)) ^ state) * 277803737u;
	return (word >> 22u) ^ word;
}

uvec2 pcg2d(uvec2 v)
{
    v = v * 1664525u + 1013904223u;

    v.x += v.y * 1664525u;
    v.y += v.x * 1664525u;

    v = v ^ (v>>16u);

    v.x += v.y * 1664525u;
    v.y += v.x * 1664525u;

    v = v ^ (v>>16u);

    return v;
}

vec3 map_to_unit_sphere(vec2 vec)
{
	// First we map [0,1] to [0,2] and subtract one to map
	// that to [-1, 1], which is the range of cosine.
	float cos_theta = 2.0 * vec.x - 1.0;

	// We can directly map phi to [0, 2PI] from [0, 1] by just
	// multiplying it with 2PI
	float phi = 2.0 * PI * vec.y;

	// sin^2(x) = 1 - cos^2(x)
	// sin(x) = sqrt(1 - cos^2(x))
	float sin_theta = sqrt(1.0 - cos_theta * cos_theta);

	float sin_phi = sin(phi);
	float cos_phi = cos(phi);

	// Just a conversion between spherical and Cartesian coordinates
	return vec3(sin_theta * cos_phi, cos_theta, sin_theta * sin_phi);
}

vec3 map_to_unit_hemisphere_cosine_weighted_criver(vec2 uv, vec3 normal)
{
	vec3 p = map_to_unit_sphere(uv);
	return normalize(p + normal);
}

struct Ray 
{
	vec3 origin;
	vec3 direction;
};

vec3 sky_color(vec3 dir)
{
	vec3 normalized_dir = normalize(dir);
	float t = 0.5 * (normalized_dir.y + 1.0);

	vec3 start_color = vec3(1.0, 1.0, 1.0);
	vec3 end_color = vec3(0.5, 0.7, 1.0);
	return (1.0 - t) * start_color + t * end_color;
}

struct LambertianMaterial
{
	vec3 Le; // emitted radiance
	vec3 diffuse; // BRDF
};

LambertianMaterial materials[] = { LambertianMaterial(vec3(0.0), vec3(0.6) / PI)  };

struct Sphere
{
	vec3 origin;
	float radius;
	uint material_index;
};

float intersect_sphere(Ray ray, Sphere sphere)
{
	vec3 oc = ray.origin - sphere.origin;
	float a = dot(ray.direction, ray.direction);
	float b = 2.0 * dot(oc, ray.direction);
	float c = dot(oc, oc) - sphere.radius * sphere.radius;
	float discriminant = b * b - 4.0 * a * c;
	if(discriminant >= 0)
	{
		float sqrt_discriminant = sqrt(discriminant);
		if(abs(discriminant) <= EPSILON)
		{
			float t = -b / (2.0 * a);
			if(t >= TMIN && t <= TMAX)
			{
				return t;
			}
		}
		else
		{
			float t1 = (-b + sqrt_discriminant) / (2.0 * a);
			float t2 = (-b - sqrt_discriminant) / (2.0 * a);
			if(t1 > t2)
			{
				float tmp = t1;
				t1 = t2;
				t2 = tmp;
			}

			if(t1 >= TMIN && t1 <= TMAX)
			{
				return t1;
			}
			else if (t2 >= TMIN && t2 <= TMAX)
			{
				return t2;
			}
		}
	}

	return -1.0;
}

struct Scene
{
	Sphere spheres[2];
};

struct HitData
{
	float t;
	vec3 normal;
	vec3 point;
	uint material_index;

	bool hit_anything;
};

HitData intersect(Ray ray, Scene scene)
{
	HitData result;
	result.hit_anything = false;
	result.t = TMAX;

	for(uint i = 0; i < scene.spheres.length(); i++)
	{
		float current_t = intersect_sphere(ray, scene.spheres[i]);
		if(current_t >= TMIN && current_t <= TMAX && current_t < result.t)
		{
			result.t = current_t;
			result.hit_anything = true;
			result.point = ray.origin + ray.direction * current_t;
			result.normal = (result.point - scene.spheres[i].origin) / scene.spheres[i].radius;
			result.material_index = scene.spheres[i].material_index;
		}
	}

	return result;
}

vec3 estimator_path_tracing_lambertian(Ray ray, Scene scene)
{
	vec3 color = vec3(0.0);

	// ( BRDF * dot(Nx, psi) ) / PDF(psi)
	vec3 throughput_term = vec3(1.0);

	// Vignette effect (basically undoing We=1/cos^3(theta) )
	// float32 theta = acosf(-ray.direction.z);
	// throughput_term = throughput_term * powf(cosf(theta), 3);

	for (uint b = 0; b < BOUNCE_COUNT; b++)
	{
		HitData data = intersect(ray, scene);
		if(!data.hit_anything) // ray goes off into infinity
		{
			if (b <= BOUNCE_COUNT)
				color += throughput_term * sky_color(ray.direction) * ENVIRONMENT_MAP_LE;
			break;
		}

		// DEBUG NORMALS
		// color = (data.normal + vec3(1.0)) * 0.5;
		// continue;

		LambertianMaterial mat = materials[data.material_index];

		// add the light that the material emits
		if (b <= BOUNCE_COUNT)
			color += throughput_term * mat.Le;

		vec3 BRDF = PI * mat.diffuse;

		// update throughput
		// The PI is here because we are sampling w.r.t the pdf
		// p(psi) = cos(theta) / PI       (cosine weighted sampling)
		// This cosine term cancels out with the dot product in
		// the throughput term and all that is left is the BRDF
		throughput_term *= BRDF;

		// pdf(psi) = cos(theta) / PI
		vec2 rand_vec = hash_uvec2_to_vec2(seed_vec);
		seed_vec = pcg2d(seed_vec + uvec2(b));
		vec3 dir = map_to_unit_hemisphere_cosine_weighted_criver(rand_vec, data.normal);

		// Intersection point and new ray
		ray = Ray(data.point + EPSILON * data.normal, dir);
	}

	return color;
}

vec4 render_function(uvec2 screen_size, ivec2 pixel_coords)
{
	uint width = screen_size.x;
	uint height = screen_size.y;
	float aspect_ratio = float(width) / height;

	float grid_height = 2.0;
	float grid_width = aspect_ratio * grid_height;

	vec3 grid_x = vec3(grid_width, 0.0, 0.0);
	vec3 grid_y = vec3(0.0, -grid_height, 0.0);

	vec3 eye = vec3(0.0, 0.0, 0.0);
	vec3 grid_origin = eye - (grid_x * 0.5) - (grid_y * 0.5);
	grid_origin.z = -2.0;

	Scene scene;
	scene.spheres[0] = Sphere(vec3(0.0, 0.0, -5.0), 1.0, 0);
	scene.spheres[1] = Sphere(vec3(0.0, -101.0, -5.0), 100.0, 0);

	int x = pixel_coords.x;
	int y = pixel_coords.y;

	vec3 color = vec3(0.0);
	for(uint s = 0; s < NUM_SAMPLES; s++)
	{
		vec2 offset_to_pixel_center = vec2(0.5, 0.5);

		vec2 uv_offset = hash_uvec2_to_vec2(seed_vec) - offset_to_pixel_center;
		seed_vec = pcg2d(seed_vec + uvec2(u_time));

		float u = (float(x) + uv_offset.x) / float(width);
		float v = (float(y) + uv_offset.y) / float(height);

		vec3 point_on_grid = grid_origin + u * grid_x + v * grid_y;
		vec3 ray_direction = normalize(point_on_grid - eye);

		Ray ray = Ray(eye, ray_direction);

		vec3 calculated_color = estimator_path_tracing_lambertian(ray, scene);

		// INF and NaN check
		if(isnan(calculated_color.x) || 
		   isnan(calculated_color.y) || 
		   isnan(calculated_color.z))
			return vec4(1.0, 0.0, 0.0, 1.0);

		if(isinf(calculated_color.x) || 
		   isinf(calculated_color.y) || 
		   isinf(calculated_color.z))
			return vec4(1.0, 0.0, 0.0, 1.0);

		color += calculated_color;
	}

	color /= float(NUM_SAMPLES);
	color.x = sqrt(color.x);
	color.y = sqrt(color.y);
	color.z = sqrt(color.z);

	return vec4(color, 1.0);
}

void main() 
{
	ivec2 pixel_coords = ivec2(gl_GlobalInvocationID.xy);

	seed_vec = uvec2(pixel_coords);
	fract_time = fract(f_time);
	
	uvec2 screen_size = imageSize(screen);
	vec4 color = render_function(screen_size, pixel_coords);

	imageStore(screen, pixel_coords, color);
}